# MFDP-RecSys
Это репозиторий для проекта по курсу MFDP, трек RecSys 

Участник: Трубин Даниил Олегович

## 1. Данные и концепция
### Концепция
Идея - разработка сервиса (пока сайт, в светлом будущем и мобильное приложение :)), который будет рекомендовать книги, фильмы сериалы (а может быть еще статьи, например, на Хабре, подкасты, курсы и многое многое другое) в зависимости от того, сколько свободного времени есть у пользователя. Можно построить рекомендательную систему для нового контента и для контента, добавленного в "Избранное".

Вообще, в условиях нехватки данных для нового сервиса с новыми клиентами, есть желание построить модель, где, возможно, используются контекстуальные многорукие бандиты + классический RecSys. Из бонусов, данная иситема сможет подстраиваться на каждого уникального пользователя. Но пока воспользуемся для начала открытые датасеты о книгах, фильмах и сериалах (потом можно собрать датасет по статьям на Хабре и подкастам). А потом можно разработать алгоритмы онлайн-дообучения собрать маленькую тестовую группу, на которой проверить насколько хорошо работают эти алгоритмы обучения или настроить имитационную модель и проверять обучение на ней. 

Дальше можно собирать информацию о паттернах поведения пользователя, распозновать эмоции и все это учитывать при рекомендации

### Данные 
Так как идея в том, чтобы рекомендовать в зависимости от количества свободного времени, то нужно иметь, как возможность рекомендовать что-то длинное - фильм, что-то относительно короткое - сериалы, или что-то не сильно привязаное ко времени - книги (статьи)

Данные: 
Книги - Book-Crossing Dataset (http://www2.informatik.uni-freiburg.de/~cziegler/BX/)

Фильмы и сериалы Kion - RecSys Course Competition (https://ods.ai/competitions/competition-recsys-21/data)

Есть еще и фильмы от movielens, но из-за объема + уже есть инфа про фильмы, данный датасет пока откладывается (до лучших времен)

Фильмы - Movielens (https://grouplens.org/datasets/movielens/)

Немного разношерстно (русский и английский языки), но для начала сойдет. 

Данные несколько отличаются от сайтов (были подправлены руками баги). zip-архив с данными: https://drive.google.com/drive/folders/16ZmugO-KkVHnosSSppLEUUzmjLAkoyp0?usp=sharing


## 2. Формулировка задачи и метрики 

Нужна рекомендательная система, значит нужно выбрать из всего контента n штук (Пусть n = 20, будем рекомендовать контент в 4 страницы по 5 рекомендаций на странице). Успехом будет, если пользователь заинтересовался предложеным контентом, и чем он выше (на перовм месте на первой странице, лучше чем на первом месте, но на второй странице), тем лучше. Поэтому успехом будет интеракция (взаимодействие) пользователя с контентом. 

Будем считать, что паре клиент-контент (далее иногда user-item) ставится в соответствии 1, если интеракция была, -1, если интеракция неудачная (пользователь не оценил контент, поставил мало баллов, выключил фильм в начале) и 0, если интеракции не было. Из пар user-item, у которых не было взаимодействия нужно выбрать такие, которые скорее всего заинтересуют пользователя. 

*(Еще одна мысль: Можно ставить 1, если взаимодейстие было, 0, если оно было не удачным и оставлять пустым, если интеракции не было, тогда можно предсказывать каким-то образом вероятность того, что пользователь откликнется. Скорее всего в будущем нужно будет попробовать разные алгоритмы рекомендаций и в некоторых такая вероятносная постановка будет работать лучше. Сейчас сказать сложно)*

Из таких размышлений, кажется, что логичнее всего выбрать метрику MAP@20. Она имеет логичное обоснование - чем выше метрика, тем чаще алгоритм выстраивает рекомендации так, что выше всего оказывается контент, который нравится пользователю. Так как на данном этапе пользователь может гипотетически выбрать только один конкретный контент за раз (лайкнуть/добавит в избранное/отметить как интересное), то можно домножить MAP@20 на 20 и получить еще более приятно трактуемую метрику, грубо трактуемую как степень близости выбронного клиентом контента к первому месту. (А если разделить 1 на получившуюся метрику, то также грубо можно трактовать ее как среднее место выбранного контента среди рекомендаций, и эту метрику надо уменьшать - 1/1 - в среднем на первом месте, 1/0.5 - в среднем на втором месте и так далее)


## 3. Baseline
В качестве отправной точки взята модель рекоммендации контента, у которого наибольшая разница положительных и отрицательных взаимодействий. Так как у книг и фильмов несколько разный масштаб, то сначала случайным образом формирутся количество и порядок типа контента (книги или фильмы/сериалы), а потом на основе топов составляются окончательные рекомендации.

В модель добавлена возможность удалять контент, который уже был увиден пользователем, однако это сильно замедляет работу модели. С другой стороны не предпологается, что нужно будет делать много рекомендаций сразу, а нужно будет делать их в потоковом режиме. 

Для данной модели MAP@20 составил **0.00297**. Если пытаться это интерпритировать, то заинтересовавший пользователя контент находится в среднем на 17 позиции. Если брать по 5 item на страницу, то это 4 страница. Но с другой стороны в среднем он находится в первой 20, что уже хорошо (особенно для baseline)
