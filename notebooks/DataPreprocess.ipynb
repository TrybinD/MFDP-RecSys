{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da7baab0",
   "metadata": {},
   "source": [
    "# RecSys. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a189b11a",
   "metadata": {},
   "source": [
    "Идея - разработка сервиса (пока сайт, в светлом будущем и мобильное приложение :)), который будет рекомендовать книги, фильмы сериалы (а может быть еще статьи, например, на Хабре, подкасты, курсы и многое многое другое) в зависимости от того, сколько свободного времени есть у пользователя. Можно построить рекомендательную систему для нового контента и для контента, добавленного в \"Избранное\".\n",
    "\n",
    "Вообще, в условиях нехватки данных для нового сервиса с новыми клиентами, есть желание построить модель, где, возможно, используются контекстуальные многорукие бандиты + классический RecSys. Из бонусов, данная иситема сможет подстраиваться на каждого уникального пользователя. Но пока воспользуемся для начала открытые датасеты о книгах, фильмах и сериалах (потом можно собрать датасет по статьям на Хабре и подкастам). А потом можно собрать маленькую тестовую группу, на которой проверить насколько хорошо работают алгоритмы такого обучения или настроить имитационную модель и проверять обучение на ней. \n",
    "\n",
    "Дальше можно собирать информацию о паттернах поведения пользователя, распозновать эмоции и все это учитывать при рекомендации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ff63d5",
   "metadata": {},
   "source": [
    "## Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5083855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89d7039",
   "metadata": {},
   "source": [
    "Данные: Так как идея в том, чтобы рекомендовать в зависимости от количества свободного времени, то нужно иметь, как возможность рекомендовать что-то длинное - фильм, что-то относительно короткое - сериалы, или что-то не сильно привязаное ко времени - книги (статьи)\n",
    "\n",
    "Данные: \n",
    "Книги - Book-Crossing Dataset (http://www2.informatik.uni-freiburg.de/~cziegler/BX/)\n",
    "\n",
    "Фильмы и сериалы Kion - RecSys Course Competition (https://ods.ai/competitions/competition-recsys-21/data)\n",
    "\n",
    "Есть еще и фильмы от movielens, но из-за объемом + то, что уже есть инфа про фильмы, данный датасет пока откладывается (до лучших времен)\n",
    "\n",
    "Фильмы - Movielens (https://grouplens.org/datasets/movielens/)\n",
    "\n",
    "Немного разношерстно (русский и английский языки), но для начала сойдет. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "138871c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_ds_path = Path('../datasets/books/')\n",
    "kion_ds_path = Path('../datasets/kion/')\n",
    "\n",
    "# films_ds_path = Path('datasets/films/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75beb398",
   "metadata": {},
   "source": [
    "Все данные, которые есть на данном этапе, представленны ниже. Но baseline и БД c клиентами пока что построим на основе рейтинг таблиц. БД с контентом возьмем готовые или вытянем из рейтинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b577a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закомментрировал, чтобы не было проблем с памятью. Не удалил, потому что логично вливаются в рассказ и ход мыслей\n",
    "\n",
    "# df_books_rating = pd.read_csv(books_ds_path / 'Book-Ratings.csv', encoding='ISO-8859-1', sep=';')\n",
    "# df_books = pd.read_csv(books_ds_path / 'Books.csv', encoding='ISO-8859-1', sep=';')\n",
    "# df_boooks_users = pd.read_csv(books_ds_path / 'Users.csv', encoding='ISO-8859-1', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c2cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_films = pd.read_csv(films_ds_path / 'movies.csv')\n",
    "# df_films_rating = pd.read_csv(films_ds_path / 'ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d9886f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_kion = pd.read_csv(kion_ds_path / 'items.csv')\n",
    "# df_kion_users = pd.read_csv(kion_ds_path / 'users.csv')\n",
    "# df_kion_rating = pd.read_csv(kion_ds_path / 'interactions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ffeeb",
   "metadata": {},
   "source": [
    "## Формулировка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f0919",
   "metadata": {},
   "source": [
    "Нужна рекомендательная система, значит нужно выбрать из всего контента n штук (Пусть n = 20, будем рекомендовать контент в 4 страницы по 5 рекомендаций на странице). Успехом будет, если пользователь заинтересовался предложеным контентом, и чем он выше (на перовм месте на первой странице, лучше чем на первом месте, но на второй странице), тем лучше. Поэтому успехом будет интеракция (взаимодействие) пользователя с контентом. \n",
    "\n",
    "Будем считать, что паре клиент-контент (далее иногда user-item) ставится в соответствии 1, если интеракция была, -1, если интеракция неудачная (пользователь не оценил контент, поставил мало баллов, выключил фильм в начале) и 0, если интеракции не было. Из пар user-item, у которых не было взаимодействия нужно выбрать такие, которые скорее всего заинтересуют пользователя. \n",
    "\n",
    "*(Еще одна мысль: Можно ставить 1, если взаимодейстие было, 0, если оно было не удачным и оставлять пустым, если интеракции не было, тогда можно предсказывать каким-то образом вероятность того, что пользователь откликнется. Скорее всего в будущем нужно будет попробовать разные алгоритмы рекомендаций и в некоторых такая вероятносная постановка будет работать лучше. Сейчас сказать сложно)*\n",
    "\n",
    "Из таких размышлений, кажется, что логичнее всего выбрать метрику MAP@20. Она имеет логичное обоснование - чем выше метрика, тем чаще алгоритм выстраивает рекомендации так, что выше всего оказывается контент, который нравится пользователю. Так как пользователь может выбрать только один конкретный контент за раз, то можно домножить MAP@20 на 20 и получить еще более приятно трактуемую метрику, грубо трактуемую как степень близости выбронного клиентом контента к первому месту. (А если разделить 1 на получившуюся метрику, то также грубо можно трактовать ее как среднее место выбранного контента среди рекомендаций, и эту метрику надо уменьшать - 1/1 - в среднем на первом месте, 1/0.5 - в среднем на втором месте и так далее)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb9f2a1",
   "metadata": {},
   "source": [
    "## Откладываем тестовую выборку"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1856e634",
   "metadata": {},
   "source": [
    "В будущем user-item матрицы, их разложения и многорукие бандиты, а пока предобработка и подготовка данных. Будем считать, что все эти пользоатели - пользователи нашего сервиса, просто кто-то выбирал только фильмы и сериалы, а кто-то только книги. Пока нет реального потока клиентов (хотя бы тестовых или имитированных) будем действовать по классике - train и test разбивка. Пока что будем считать, что спрос на контент пропорционален размерам датасетов, поэтому из каждого датасета возмем примерно по 20 процентов интеракций. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b958f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e05990",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67f96f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведем датасеты с интеракциями к единому виду с едиными столбцоми.\n",
    "# Пока не будем разделять на положительные и отрицательные интеракции\n",
    "\n",
    "# Все id дополним буквами b, k, чтобы если вдруг есть одинаковые id, то они не перемешались. \n",
    "df_books_rating = pd.read_csv(books_ds_path / 'Book-Ratings.csv', encoding='ISO-8859-1', sep=';')\n",
    "df_books_interactions = df_books_rating.rename({'User-ID': 'user', 'ISBN': 'item'}, axis=1)\n",
    "df_books_interactions['Book-Rating'] = df_books_interactions['Book-Rating'].replace(0, 5)\n",
    "df_books_interactions['interaction_type'] = 1\n",
    "df_books_interactions.loc[df_books_interactions[df_books_interactions['Book-Rating'] < 5].index, 'interaction_type'] = -1\n",
    "df_books_interactions['source'] = 'books'\n",
    "df_books_interactions[['user', 'item']] = 'b'+df_books_interactions[['user', 'item']].astype(str)\n",
    "df_books_interactions = df_books_interactions.drop('Book-Rating', axis=1)\n",
    "del df_books_rating \n",
    "\n",
    "df_kion_rating = pd.read_csv(kion_ds_path / 'interactions.csv')\n",
    "df_kion_interactions = df_kion_rating[['user_id', 'item_id', 'watched_pct']].rename({'user_id': 'user', 'item_id': 'item'}, axis=1)\n",
    "df_kion_interactions['interaction_type'] = 1\n",
    "df_kion_interactions.loc[df_kion_interactions[df_kion_interactions['watched_pct'] < 30].index, 'interaction_type'] = -1\n",
    "df_kion_interactions[['user', 'item']] = 'k'+df_kion_interactions[['user', 'item']].astype(str)\n",
    "df_kion_interactions['source'] = 'kion'\n",
    "df_kion_interactions = df_kion_interactions.drop('watched_pct', axis=1)\n",
    "del df_kion_rating\n",
    "\n",
    "# df_films_rating = pd.read_csv(films_ds_path / 'ratings.csv')\n",
    "# df_films_interactions = df_films_rating[['userId', 'movieId']].rename({'userId': 'user', 'movieId': 'item'}, axis=1)\n",
    "# df_films_interactions = 'f'+df_films_interactions.astype(str)\n",
    "# df_films_interactions['sourse'] = 'films'\n",
    "# del df_films_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7400da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = [], []\n",
    "for i in [df_books_interactions,  df_kion_interactions]:\n",
    "    df_train, df_test = train_test_split(i, test_size=0.2, random_state=RANDOM_SEED)\n",
    "    del i\n",
    "    train.append(df_train)\n",
    "    test.append(df_test)\n",
    "df_train = pd.concat(train)\n",
    "df_test = pd.concat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1863f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e66b713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet(data_path / 'df_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f83f00b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_parquet(data_path / 'df_test.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc2cd6",
   "metadata": {},
   "source": [
    "### Соберем маленькую БД по Пользователям"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1e8aa3",
   "metadata": {},
   "source": [
    "Так как идея в том, чтобы рекомендовать что-то новое (или что-то из избранног), то нужно на новое и избранное разбить. Для этого заведем небольшую БД по пользователям, в котороый будут записаны их \"Избранное\" - то, что они уже смотрели/читали. Очевидно, что эта БД должна быть на основе train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c9eec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_bd = df_train.groupby('user').agg({'item': lambda x: ', '.join(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a935cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_bd.to_parquet(data_path / 'users_bd.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30f327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
