# Подробный отчет о моделях

## Вводные данные и ограничения
Стоит заранее подумать об ограничениях, которые накладываются на модели в данном проекте:

1. Ограничения GitHub`а - гитхаб не позволяет хранить очень большие файлы, поэтому нужно учитывать, что модели должны быть не очень тяжеловесными. По этой причине кажется, что memory-based алгоритмы отпадают
2. Ограничения хостинга Streamlit - модели не должны быть слишком требовательны к памяти и вычислительным мощностям, поэтому, во-первых, желательно, чтобы модели загружались уже обученными и не требовали обучения на сервере, а во-вторых, чтобы они не требовали много ресурсов во время процесса рекомендации.
3. Специфика - хочется, чтобы модель быстро адаптировалась под конкретного пользователя без глобального переобучения, потому что, по факту, ВСЕ пользователи сервиса - холодные. Значит архитектура модели нужна такая, что модель *при рекомендации* будет принимать контент, добавленный пользователем в избранное и на основе него что-то рекоммендовать. То есть пользователь будет характеризоваться  *только вектором выбранного им контента*.

С одной стороны, эти ограничения сильные и обрубают множество подходов, с другой стороны, глаза не разбегаются и есть возможность сконцентрироваться на доведения до ума подходящих вариантов (пока в голове только что-то типо многоруких бандитов, но размерность для них слишком могромная, нужен ресерч)
P.S. Нашел несколько библиотек для похожих историй, но в них разобраться и настроить под себя - отдельная история.. 

Будем двигаться от простого к сложному (надеюсь успею дойду до сложного за 2 недели, но Илон Маск запретил делать слишком крутые ИИ :laughing:).

Формально, тестовые метрики будут не очень показательные, потому что пользователи сервиса будут новые, но все равно на них нужно опираться + здравый смысл и субъективное ощущение). На этапе упаковки MVP и подготовки к питчингу постараюсь позвать друзей/коллег потестить и постараюсь провести A/B тест моделей, это кажется более показательным и репрезентративным.

## 1. Архитектура 

Кажется, что лучшим подходом в данном случае будет написать модель с помощью патерна **Стратегия**, которая принимает более простые атомарные модели, отвечающие за свою зону ответственности (отдельно книги, отдельно фильмы, отдельно статьи отдельно стратегия выбора домена). Это убъет двух зайцев:

1. Обучить отдельные атомарные модели проще, потому что данные сейчас не связаны между собой - книги отдельно, фильмы отдельно. Кажется, что формально - это правильнее. + Если успею дойти до построения рекомендаций статей Хабра, то там нет данных о взаимодействиях, и нельзя построить модель колобаративной фильтрации. Нужно что-то еще.
2. Так будет проще тестировать разные модели + организовать A/B тестирование.

## 2. Рекомендации домена
Я рещил реализовать две несложные модели рекомендации домена. 
PopularDomainRecommender - Просто рекомендует домены в зависимости от их популярности. По факту это просто вынесенный для удобства кусок кода из базовой модели. Просто как отправная точка и продумать архитектуру взаимодействия моделей.
AdaptiveDomainRecommender - Адаптирует количество доменов для рекомендации под пользователя на основе его истории. Модель не сложная и назвать ее ML-моделью особо язык не поднимается, это скорее эвристика. С другой стороны, (если выбран режим bayesian) теоритически она довольно изящна и основана на *байесовских многоруких бандитах и сопряженных распределениях - мультиномиальное и Дирихле*. Режим frequency чуть проще и просто считаиет частоты предпочтений пользователя и на основе этих частот случайно делает рекомендацию. 
Еще один плюсик адаптивной модели - она не требует стадии обучения, значит ее не нужно обучать где-то и как-то ofline и загружать на сервер, а сразу можно иимпортировать и использовать.

Кроме того в эти модели прокинуты фильтры, чтобы можно были запретить рекомендовать какой-нибудь домен (например, не хватает времени, не хочет видедь книги или что-то еще)

TODO: some kind of Имитационный эксперемент для рекомендации домена + выводы, что Адаптивная модель прикольнее





Вывод: мне больше нравится адаптивная модель, потому что она позволяет адаптироваться под пользователия in-real-time. Поэтому она будет использоваться как основная.

## 3. Коротко о моделях

Я решил самостоятельно написать несколько классов для моделей, чтобы, во-первых, они все были единообразными, а во-вторых, просто лучше почувствовать RecSys, так как раньше с ним не работал. Возможно, на углубление и изучение и написание своих классов, я потратил непрелично много времени, но надеюсь у этого будут свои плоды. Во первых все эти модели универсальны в том смысле, что можно их использовать для любых доменов, а во вторых единообразны, так что эксперименты должно быть проводить проще и встраивать их в сервис тоже.

Коротко о моделях и идеях, в них заложенных:

В некоторые модели добавил возможность выбора варианта работы - случайный и детерминированый, чтобы каждый раз были разные рекомендации. Посмотрим, что из этого выйдет.

BaseModel.TopRecommender - Baseline. Просто рекомендация топа рейтинга. Есть два варанта работы - случайный, чтобы каждый раз были новые рекомендации (и использовать в качестве случайной модели для просчета метрик) и детерминированный - просто топ. 

ItemBasedRecommenders.CosineDistanceRecommender - Разминка для написания классов-рекомендаторов. Просто считаем косинусное расстояние между всеми item, и сохраняем. А при рекомендации смотрим, что уже лежит в избраном, для каждого item из избранного находим похожие и расстояния до них, складываем расстояния для всех item из избранного и выдаем топ ближайших. Довольно простая модель, но первые эксперименты с ней показывают прикольные результаты. На нее есть надежда. 

MatrixFactorizationRecommenders.ALSBasedRecommender - Модель на основе ALS из implicit. Преимущество в том, что очень удобно использовать для холодны юзеров, у которых уже есть какие-то отклики, что нам собственно и нужно. По факту просто Удобный Адаптер для implicit. 

MatrixFactorizationRecommenders.LightFMBasedRecommender - Модель на основе LightFM. Я попытался использовать, что что эту модель можно дообучать - просто создать пустого юзера и обучить с ним, а потом, когда появятся отклики добавить их в матрицу и доучить модель. Самая тяжеловесная и долгая модель по итогу первых экспериментов. На нее не ставлю, но все равно исследую.

TODO:

ClusterRecommender - Разбить фильмы на кластеры и рекоммендовать item из кластера, где уже есть item из избранного. Предварительно фильмы можно факторизовать, чтобы упростит классификацию и сделать ее интереснее. 

ContentBasedRecommender - Рекомендатор основанный на схожести контента. Полезен для холодных item, например, если все же доберусь до статей Хабра, то можно рекомендовать с похожими названиями, или прикрутить BERT и искать схожий смысл (ну это высший пилотаж и наверное не в рамках курса)

## 4. Рекомендации книг

После небольшого углубления в данные, я решил что, нужно подсократить количество книг и пользователей. Есть какие-то странные книги у которых один отзыв, которые явно не попадут в рекомедации, и есть неинформативные пользователи с одним отзывом, которые только утяжеляют и без того немаленький датасет. Кроме того очень много одинаковых книг разных изданий, что не есть хорошо, потому что хочется рекоммендовать именно книгу, а не какое-то издание, например одних только бойцовских клубов 6 штук 2 из которых с препиской 'а Novel'. Удалить все книги не выйдет, но вот подчистить размер датасета вполне. А еще, раз было принято решение разделить рекомендации, то можно использовать отдельно датасеты и не обязательно приводить их к общему виду, для книг можно использовать рейтинг, который был изначально. Нужно ненадолго вернуться к предобработке данных. Из-за этого, конечно, полетит бейзлайн и придется его считать заново.

Зато получилось значительно сократить user-item матрицу, что в разы увеличило скорость работы. 

Чуть-чуть про то, как модели обучались и сравнивались между собой. Это справедливо и для фильмов и сериалов.

Все происходит в файле Books Domain.ipynb
Просто создается функция, которая принимает на вход модель, параметры, с которыми эту модель нужно обучать, параметры для предсказания и мой тестовый топ лист, чтобы самому прочувствовать, как же рекомендует модель. Далее на 1000 данных о взаимодействиях считается MAP@10, время одной рекомендации, и рекомендация для тестовы фаворитов. Все это сохраняется в папку mlflow_tracking (Я использую MLFlow потому что был чуть чуть с ним знаком, а выбирать из разных фреймворков, заняло бы еще время. В MLFlow есть возможность сохранять все в файлы и папки, а не БД, потому что на проектке по факту нет БД - это совсем не хорошо, но на развертываие хорошей БД времени не хватило). Модели сохранятся еще и в папку model_storage, но я ее чищу, потому что они дублируются. Мне кажется, что все довольно удобно. Локално поднимаю MLFlow UI и изучаю глазками 

Всего я провел 9 экспериментов с разными моделями. Ниже представлен скрин результата:

![MLFlow_books](https://github.com/TrybinD/MFDP-RecSys/blob/improve_models/imgs/MLFlow_books.JPG)

#### Краткий ревью и выводы:
Самые лучшие модели - ALS-модели. По поводу количества факторов и итераций - кажется, что можно оставить ванильные 100 факторов и 15 итераций, или сократить до 50 факторов. Результат не особо отличается, а весит меньше и пошустрее чутка. 200 факторов показывает результат чуть получше, но она и весит больше и субъективно она мне понравилась меньше. Рекомендации ALS модели на 50 и 100 параметров просто огонь - Дивный новый мир, Повелитель Мух, Над пропостью во ржи, 1984. Он угадал другие книги, которые мне тоже нравятся. Она фаворит и пойдет в сервис. Единственное, что ее, наверное, надо будет докрутить, чтобы можно было обновлять рекомендации и она не советовала то, что было в прошлый раз.

Модель на косинусном растоянии получилась очень тяжелой - оно и понятно, потому что она хранит матрицу расстояний, хоть и разряженную. Показывает она результат такой же как ALS, но медленее + субъективно рекомендации немного не то. Хотя тоже неплохо - Убить пересмешника, Милые Кости. Я не читал, но думаю, мне может понравится. Порадоксально, но случайный вариант этой модели (там вероятность пропорциональна близости, так что модель не то чтобы полностью случайные) мне зашел чуть больше - Камю и Уэлш. Эту модель можно попробовать докрутить, как альтернативу. Но в целом случайность сработала хуже.

Остальные модели совсем не очень. LightFM и рекомендовал долго и метрики не очень и рекомендации. Наверное, она хороша при другом подходе, но ни при текущем. 


## 5. Рекомендации фильмов и сериалов (с учетом времени)

## 6. Рекомендации статей на Хабре?

## 7. Ранжирование избранного?

## Интересные ссылки и литература
Я рещил сохранять все понравившиеся ссылки и статьи, даже если не успею их использовать и реализовать, потому что даже по завершению курса будет интересно вернуться к проекту и попилить его

1) https://arxiv.org/pdf/2106.10898.pdf
