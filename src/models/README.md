# Подробный отчет о моделях

## Вводные данные и ограничения
Стоит заранее подумать об ограничениях, которые накладываются на модели в данном проекте:

1. Ограничения GitHub`а - гитхаб не позволяет хранить очень большие файлы, поэтому нужно учитывать, что модели должны быть не очень тяжеловесными. По этой причине кажется, что memory-based алгоритмы отпадают
2. Ограничения хостинга Streamlit - модели не должны быть слишком требовательны к памяти и вычислительным мощностям, поэтому, во-первых, желательно, чтобы модели загружались уже обученными и не требовали обучения на сервере, а во-вторых, чтобы они не требовали много ресурсов во время процесса рекомендации.
3. Специфика - хочется, чтобы модель быстро адаптировалась под конкретного пользователя без глобального переобучения, потому что, по факту, ВСЕ пользователи сервиса - холодные. Значит архитектура модели нужна такая, что модель *при рекомендации* будет принимать контент, добавленный пользователем в избранное и на основе него что-то рекоммендовать. То есть пользователь будет характеризоваться  *только вектором выбранного им контента*.

С одной стороны, эти ограничения сильные и обрубают множество подходов, с другой стороны, глаза не разбегаются и есть возможность сконцентрироваться на доведения до ума подходящих вариантов (пока в голове только что-то типо многоруких бандитов, но размерность для них слишком могромная, нужен ресерч)
P.S. Нашел несколько библиотек для похожих историй, но в них разобраться и настроить под себя - отдельная история.. 

Будем двигаться от простого к сложному (надеюсь успею дойду до сложного за 2 недели, но Илон Маск запретил делать слишком крутые ИИ :laughing:).

Формально, тестовые метрики будут не очень показательные, потому что пользователи сервиса будут новые, но все равно на них нужно опираться + здравый смысл и субъективное ощущение). На этапе упаковки MVP и подготовки к питчингу постараюсь позвать друзей/коллег потестить и постараюсь провести A/B тест моделей, это кажется более показательным и репрезентративным.

## 1. Архитектура 

Кажется, что лучшим подходом в данном случае будет написать модель с помощью патерна **Стратегия**, которая принимает более простые атомарные модели, отвечающие за свою зону ответственности (отдельно книги, отдельно фильмы, отдельно статьи отдельно стратегия выбора домена). Это убъет двух зайцев:

1. Обучить отдельные атомарные модели проще, потому что данные сейчас не связаны между собой - книги отдельно, фильмы отдельно. Кажется, что формально - это правильнее. + Если успею дойти до построения рекомендаций статей Хабра, то там нет данных о взаимодействиях, и нельзя построить модель колобаративной фильтрации. Нужно что-то еще.
2. Так будет проще тестировать разные модели + организовать A/B тестирование.

## 2. Рекомендации домена
Я рещил реализовать две несложные модели рекомендации домена. 
PopularDomainRecommender - Просто рекомендует домены в зависимости от их популярности. По факту это просто вынесенный для удобства кусок кода из базовой модели. Просто как отправная точка и продумать архитектуру взаимодействия моделей.
AdaptiveDomainRecommender - Адаптирует количество доменов для рекомендации под пользователя на основе его истории. Модель не сложная и назвать ее ML-моделью особо язык не поднимается, это скорее эвристика. С другой стороны, (если выбран режим bayesian) теоритически она довольно изящна и основана на *байесовских многоруких бандитах и сопряженных распределениях - мультиномиальное и Дирихле*. Режим frequency чуть проще и просто считаиет частоты предпочтений пользователя и на основе этих частот случайно делает рекомендацию. 
Еще один плюсик адаптивной модели - она не требует стадии обучения, значит ее не нужно обучать где-то и как-то ofline и загружать на сервер, а сразу можно иимпортировать и использовать.

Кроме того в эти модели прокинуты фильтры, чтобы можно были запретить рекомендовать какой-нибудь домен (например, не хватает времени, не хочет видедь книги или что-то еще)

TODO: some kind of Имитационный эксперемент для рекомендации домена + выводы, что Адаптивная модель прикольнее





Вывод: мне больше нравится адаптивная модель, потому что она позволяет адаптироваться под пользователия in-real-time. Поэтому она будет использоваться как основная.

## 3. Рекомендации книг

После небольшого углубления в данные, я решил что, нужно подсократить количество книг и пользователей. Есть какие-то странные книги у которых один отзыв, которые явно не попадут в рекомедации, и есть неинформативные пользователи с одним отзывом, которые только утяжеляют и без того немаленький датасет. Кроме того очень много одинаковых книг разных изданий, что не есть хорошо, потому что хочется рекоммендовать именно книгу, а не какое-то издание, например одних только бойцовских клубов 6 штук 2 из которых с препиской 'а Novel'. Удалить все книги не выйдет, но вот подчистить размер датасета вполне. А еще, раз было принято решение разделить рекомендации, то можно использовать отдельно датасеты и не обязательно приводить их к общему виду, для книг можно использовать рейтинг, который был изначально. Нужно ненадолго вернуться к предобработке данных. 

## 4. Рекомендации фильмов и сериалов (с учетом времени)

## 5. Рекомендации статей на Хабре?

## 6. Ранжирование избранного?

## Интересные ссылки и литература
Я рещил сохранять все понравившиеся ссылки и статьи, даже если не успею их использовать и реализовать, потому что даже по завершению курса будет интересно вернуться к проекту и попилить его

1) https://arxiv.org/pdf/2106.10898.pdf
